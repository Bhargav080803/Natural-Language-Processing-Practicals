{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP725bo6EyUePmfQaxnYXCE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":390},"id":"cDJITdVJo_Fr","executionInfo":{"status":"error","timestamp":1692782269291,"user_tz":-330,"elapsed":1045,"user":{"displayName":"Bhargav Joshi","userId":"12481558726307722336"}},"outputId":"cb143d64-f3c7-48fb-9d77-a29baae400dd"},"outputs":[{"output_type":"error","ename":"RateLimitError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-a863115b60c5>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mdialogue_history\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"User: {user_input}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdialogue_history\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"AI:\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AI:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"User: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-a863115b60c5>\u001b[0m in \u001b[0;36mgenerate_response\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     response = openai.Completion.create(\n\u001b[0m\u001b[1;32m      7\u001b[0m       \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-davinci-003\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    766\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             )\n","\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."]}],"source":["import openai\n","\n","openai.api_key = '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'\n","\n","def generate_response(prompt):\n","    response = openai.Completion.create(\n","      engine=\"text-davinci-003\",\n","      prompt=prompt,\n","      max_tokens=50\n","    )\n","    return response.choices[0].text.strip()\n","\n","user_input = \"Hello, how are you?\"\n","dialogue_history = \"\"\n","\n","while user_input.lower() != \"exit\":\n","    dialogue_history += f\"User: {user_input}\\n\"\n","    prompt = dialogue_history + \"AI:\"\n","    response = generate_response(prompt)\n","    print(\"AI:\", response)\n","    user_input = input(\"User: \")\n"]},{"cell_type":"code","source":["import openai\n","\n","openai.api_key = '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'\n","\n","def generate_response(prompt):\n","    response = openai.Completion.create(\n","      engine=\"text-davinci-003\",\n","      prompt=prompt,\n","      max_tokens=50\n","    )\n","    return response.choices[0].text.strip()\n","    print(generate_response)"],"metadata":{"id":"zUv48kkcqo42","executionInfo":{"status":"ok","timestamp":1692782251897,"user_tz":-330,"elapsed":4,"user":{"displayName":"Bhargav Joshi","userId":"12481558726307722336"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# Sample dialogue dataset\n","input_texts = [\"How are you?\",  \"How's the weather?\",\"what is your name\"]\n","target_texts = [\"I'm good.\", \"It's sunny.\",\"bhargav\"]\n","\n","# Tokenize input and output texts\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(input_texts + target_texts)\n","\n","input_sequences = tokenizer.texts_to_sequences(input_texts)\n","target_sequences = tokenizer.texts_to_sequences(target_texts)\n","\n","# Padding sequences\n","max_seq_length = max(max(len(seq) for seq in input_sequences), max(len(seq) for seq in target_sequences))\n","input_sequences = pad_sequences(input_sequences, maxlen=max_seq_length, padding='post')\n","target_sequences = pad_sequences(target_sequences, maxlen=max_seq_length, padding='post')\n","\n","# Define vocabulary size\n","vocab_size = len(tokenizer.word_index) + 1\n","\n","# Create the model\n","embedding_dim = 128\n","hidden_units = 256\n","\n","model = Sequential([\n","    Embedding(vocab_size, embedding_dim, input_length=max_seq_length),\n","    LSTM(hidden_units, return_sequences=True),\n","    Dense(vocab_size, activation='softmax')\n","])\n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.summary()\n","\n","# Train the model\n","model.fit(input_sequences, np.expand_dims(target_sequences, -1), epochs=50)\n","\n","# Inference (dialogue generation)\n","def generate_response(input_text):\n","    input_seq = tokenizer.texts_to_sequences([input_text])\n","    input_seq = pad_sequences(input_seq, maxlen=max_seq_length, padding='post')\n","    predicted_token_index = np.argmax(model.predict(input_seq), axis=-1)\n","    response = tokenizer.sequences_to_texts(predicted_token_index)[0]\n","    return response\n","\n","# Generate responses\n","input_text = \"what is your name\"\n","response = generate_response(input_text)\n","print(\"Input:\", input_text)\n","print(\"Response:\", response)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7DYQRIpbqGDY","executionInfo":{"status":"ok","timestamp":1692782818619,"user_tz":-330,"elapsed":6352,"user":{"displayName":"Bhargav Joshi","userId":"12481558726307722336"}},"outputId":"a257fe0f-95ec-47e2-a7aa-1f980c4bb1cf"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_5 (Embedding)     (None, 4, 128)            2048      \n","                                                                 \n"," lstm_5 (LSTM)               (None, 4, 256)            394240    \n","                                                                 \n"," dense_5 (Dense)             (None, 4, 16)             4112      \n","                                                                 \n","=================================================================\n","Total params: 400,400\n","Trainable params: 400,400\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","1/1 [==============================] - 3s 3s/step - loss: 2.7714 - accuracy: 0.0833\n","Epoch 2/50\n","1/1 [==============================] - 0s 28ms/step - loss: 2.7510 - accuracy: 0.5833\n","Epoch 3/50\n","1/1 [==============================] - 0s 30ms/step - loss: 2.7298 - accuracy: 0.5833\n","Epoch 4/50\n","1/1 [==============================] - 0s 37ms/step - loss: 2.7069 - accuracy: 0.5833\n","Epoch 5/50\n","1/1 [==============================] - 0s 25ms/step - loss: 2.6813 - accuracy: 0.5833\n","Epoch 6/50\n","1/1 [==============================] - 0s 27ms/step - loss: 2.6520 - accuracy: 0.5833\n","Epoch 7/50\n","1/1 [==============================] - 0s 25ms/step - loss: 2.6178 - accuracy: 0.5833\n","Epoch 8/50\n","1/1 [==============================] - 0s 27ms/step - loss: 2.5775 - accuracy: 0.5833\n","Epoch 9/50\n","1/1 [==============================] - 0s 33ms/step - loss: 2.5297 - accuracy: 0.5833\n","Epoch 10/50\n","1/1 [==============================] - 0s 27ms/step - loss: 2.4727 - accuracy: 0.5833\n","Epoch 11/50\n","1/1 [==============================] - 0s 27ms/step - loss: 2.4046 - accuracy: 0.5833\n","Epoch 12/50\n","1/1 [==============================] - 0s 30ms/step - loss: 2.3234 - accuracy: 0.5833\n","Epoch 13/50\n","1/1 [==============================] - 0s 32ms/step - loss: 2.2272 - accuracy: 0.5833\n","Epoch 14/50\n","1/1 [==============================] - 0s 25ms/step - loss: 2.1143 - accuracy: 0.5833\n","Epoch 15/50\n","1/1 [==============================] - 0s 23ms/step - loss: 1.9849 - accuracy: 0.5833\n","Epoch 16/50\n","1/1 [==============================] - 0s 30ms/step - loss: 1.8428 - accuracy: 0.5833\n","Epoch 17/50\n","1/1 [==============================] - 0s 26ms/step - loss: 1.6974 - accuracy: 0.5833\n","Epoch 18/50\n","1/1 [==============================] - 0s 27ms/step - loss: 1.5628 - accuracy: 0.5833\n","Epoch 19/50\n","1/1 [==============================] - 0s 27ms/step - loss: 1.4505 - accuracy: 0.5833\n","Epoch 20/50\n","1/1 [==============================] - 0s 25ms/step - loss: 1.3625 - accuracy: 0.5833\n","Epoch 21/50\n","1/1 [==============================] - 0s 27ms/step - loss: 1.2957 - accuracy: 0.5833\n","Epoch 22/50\n","1/1 [==============================] - 0s 24ms/step - loss: 1.2471 - accuracy: 0.5833\n","Epoch 23/50\n","1/1 [==============================] - 0s 24ms/step - loss: 1.2138 - accuracy: 0.5833\n","Epoch 24/50\n","1/1 [==============================] - 0s 27ms/step - loss: 1.1919 - accuracy: 0.5833\n","Epoch 25/50\n","1/1 [==============================] - 0s 28ms/step - loss: 1.1775 - accuracy: 0.5833\n","Epoch 26/50\n","1/1 [==============================] - 0s 26ms/step - loss: 1.1678 - accuracy: 0.5833\n","Epoch 27/50\n","1/1 [==============================] - 0s 24ms/step - loss: 1.1605 - accuracy: 0.5833\n","Epoch 28/50\n","1/1 [==============================] - 0s 27ms/step - loss: 1.1541 - accuracy: 0.5833\n","Epoch 29/50\n","1/1 [==============================] - 0s 25ms/step - loss: 1.1473 - accuracy: 0.5833\n","Epoch 30/50\n","1/1 [==============================] - 0s 25ms/step - loss: 1.1391 - accuracy: 0.5833\n","Epoch 31/50\n","1/1 [==============================] - 0s 26ms/step - loss: 1.1290 - accuracy: 0.5833\n","Epoch 32/50\n","1/1 [==============================] - 0s 25ms/step - loss: 1.1167 - accuracy: 0.5833\n","Epoch 33/50\n","1/1 [==============================] - 0s 25ms/step - loss: 1.1023 - accuracy: 0.5833\n","Epoch 34/50\n","1/1 [==============================] - 0s 33ms/step - loss: 1.0861 - accuracy: 0.5833\n","Epoch 35/50\n","1/1 [==============================] - 0s 27ms/step - loss: 1.0684 - accuracy: 0.5833\n","Epoch 36/50\n","1/1 [==============================] - 0s 24ms/step - loss: 1.0499 - accuracy: 0.5833\n","Epoch 37/50\n","1/1 [==============================] - 0s 25ms/step - loss: 1.0309 - accuracy: 0.5833\n","Epoch 38/50\n","1/1 [==============================] - 0s 23ms/step - loss: 1.0119 - accuracy: 0.5833\n","Epoch 39/50\n","1/1 [==============================] - 0s 26ms/step - loss: 0.9934 - accuracy: 0.5833\n","Epoch 40/50\n","1/1 [==============================] - 0s 26ms/step - loss: 0.9755 - accuracy: 0.5833\n","Epoch 41/50\n","1/1 [==============================] - 0s 25ms/step - loss: 0.9584 - accuracy: 0.5833\n","Epoch 42/50\n","1/1 [==============================] - 0s 26ms/step - loss: 0.9422 - accuracy: 0.5833\n","Epoch 43/50\n","1/1 [==============================] - 0s 27ms/step - loss: 0.9269 - accuracy: 0.5833\n","Epoch 44/50\n","1/1 [==============================] - 0s 25ms/step - loss: 0.9124 - accuracy: 0.5833\n","Epoch 45/50\n","1/1 [==============================] - 0s 29ms/step - loss: 0.8985 - accuracy: 0.5833\n","Epoch 46/50\n","1/1 [==============================] - 0s 35ms/step - loss: 0.8852 - accuracy: 0.5833\n","Epoch 47/50\n","1/1 [==============================] - 0s 25ms/step - loss: 0.8723 - accuracy: 0.5833\n","Epoch 48/50\n","1/1 [==============================] - 0s 24ms/step - loss: 0.8594 - accuracy: 0.5833\n","Epoch 49/50\n","1/1 [==============================] - 0s 24ms/step - loss: 0.8463 - accuracy: 0.5833\n","Epoch 50/50\n","1/1 [==============================] - 0s 27ms/step - loss: 0.8329 - accuracy: 0.5833\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ee6ff07f5b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 447ms/step\n","Input: what is your name\n","Response: \n"]}]}]}