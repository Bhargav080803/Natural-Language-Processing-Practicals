{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMCSldFfGTHTc+qaA5VcZhs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tdLMreHMVSVA","executionInfo":{"status":"ok","timestamp":1692206073520,"user_tz":-330,"elapsed":4829,"user":{"displayName":"Bhargav Joshi","userId":"12481558726307722336"}},"outputId":"bb27b523-661b-48bc-eb96-2a760f879ff9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.6)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"]}],"source":["pip install nltk"]},{"cell_type":"code","source":["#tokkenization\n","import nltk\n","nltk.download('punkt')  # Download the necessary data\n","\n","from nltk.tokenize import word_tokenize\n","\n","text = \"hello world.\"\n","tokens = word_tokenize(text)\n","print(tokens)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oq4gCpIQV5Ch","executionInfo":{"status":"ok","timestamp":1692206144674,"user_tz":-330,"elapsed":419,"user":{"displayName":"Bhargav Joshi","userId":"12481558726307722336"}},"outputId":"70708728-0e28-4033-81bf-90cd267c2608"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["['hello', 'world', '.']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","source":["#pos tagging\n","import nltk\n","nltk.download('averaged_perceptron_tagger')  # Download the necessary data\n","\n","from nltk import pos_tag\n","from nltk.tokenize import word_tokenize\n","\n","text = \"POS tagging is useful for linguistic analysis.\"\n","tokens = word_tokenize(text)\n","pos_tags = pos_tag(tokens)\n","print(pos_tags)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R-ZhDjT-WMCH","executionInfo":{"status":"ok","timestamp":1692206195547,"user_tz":-330,"elapsed":413,"user":{"displayName":"Bhargav Joshi","userId":"12481558726307722336"}},"outputId":"bc1685ef-86e7-4ef2-8c28-1d875a8b4ab6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"output_type":"stream","name":"stdout","text":["[('POS', 'NNP'), ('tagging', 'NN'), ('is', 'VBZ'), ('useful', 'JJ'), ('for', 'IN'), ('linguistic', 'JJ'), ('analysis', 'NN'), ('.', '.')]\n"]}]},{"cell_type":"code","source":["#lemmatization\n","import nltk\n","nltk.download('wordnet')  # Download the necessary data\n","\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import word_tokenize\n","\n","lemmatizer = WordNetLemmatizer()\n","\n","text = \"boy and girl are good\"\n","tokens = word_tokenize(text)\n","lemmatized_words = [lemmatizer.lemmatize(word) for word in tokens]\n","print(lemmatized_words)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VAvzt0pIWtCH","executionInfo":{"status":"ok","timestamp":1692206355937,"user_tz":-330,"elapsed":403,"user":{"displayName":"Bhargav Joshi","userId":"12481558726307722336"}},"outputId":"1c29a755-bb67-46dd-ea64-e8742a9b08b0"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["['boy', 'and', 'girl', 'are', 'good']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}]},{"cell_type":"code","source":["#stemming\n","import nltk\n","nltk.download('punkt')  # Download the necessary data\n","\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import word_tokenize\n","\n","stemmer = PorterStemmer()\n","\n","text = \"Stemming reduces words to their base form.\"\n","tokens = word_tokenize(text)\n","stemmed_words = [stemmer.stem(word) for word in tokens]\n","print(stemmed_words)\n"],"metadata":{"id":"Io4L3EJ9XGvv","executionInfo":{"status":"ok","timestamp":1692206407402,"user_tz":-330,"elapsed":391,"user":{"displayName":"Bhargav Joshi","userId":"12481558726307722336"}},"outputId":"2f643269-bbdd-43f4-aee3-e877894b0b73","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["['stem', 'reduc', 'word', 'to', 'their', 'base', 'form', '.']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]}]}